---
title: "Replies to editor and associate editor Journal of Hydrology"
author: "Willem Vervoort/Eliana Nervi/Jimena Alonso"
date: "`r Sys.Date()`"
output:   
  bookdown::pdf_book:
    base_format: rticles::elsevier_article
bibliography: forest_and_water.bib
---

```{r setup, include=FALSE, echo =F}
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
require(lubridate)
suppressWarnings(require(knitr))
suppressWarnings(require(bookdown))
suppressWarnings(require(pander))
```

# Introduction

This document records the replies to the reviewer for the first submission of *"Factors determining how catchments respond to forest cover change. Re-analysing global data sets"* to Journal of Hydrology, which was rejected before review.  
\
Reviewer comments in \textcolor{blue}{blue}. Our responses in normal text.  
\
**The most important point from the reviews is the fact that we have not communicated the need for this paper. We need to rewrite the introduction to do this better.**  
\

# Editor comments

\textcolor{blue}{The first is to streamline the statistics.  As suggested by the AE, a formal model selection process, followed by using only the selected model(s) to evaluate change, would be a suitable approach.}    
\
**check this**
We politely disagree with the suggestion of a formal model selection process, as we outline in our reply to the AE. If the statistical modelling aimed at developing the best predictive model, then this would be the right approach. However, in this case the statistical modelling is aimed at hypothesis testing and explanation of variance in the data set.     
\
\textcolor{blue}{In doing so, please carefully note the AEs' concerns about some of the statistical methodology - concerns which range from interpretation to the use of appropriate performance metrics across models of varying structure, to the selection of the appropriate metrics of forest cover change for analysis.}   
\
Please see our comments in reply to the AE below.    
\  
\textcolor{blue}{The second - hopefully supported by a streamlining of the statistics - is to simplify and improve the coherence of the argument.  Framing - as the AE states - a "systematic" exploration of the importance of parameters, will improve the readability and interpretability of the work.  At present, I think because the statistical analysis itself is convoluted - so too the thread of the argument and clarity of the messages are hard to follow.}    
\
Please see our comments in reply to the AE below.  \
\

\textcolor{blue}{The final - and perhaps in truth the most problematic issue that may stand in the way of the MS being published - relates to novelty.  The AE highlights several recent works with similar questions, approaches and findings at global scales.  I could add to that list with more regional studies (e.g. Levy et al 2018).  So carefully identifying the knowledge gap being addressed, with respect to these recent studies, and making the case for the present study being "needed" will also be essential.}    \
\

Thank you for the suggestion of the @levy2018 paper, which is an excellent example of a careful statistical analysis taking into account possible variations in climate and dynamic landuse change. This is exactly the kind of statistical analysis that we believe needs to be undertaken to better understand how forest cover impacts  The paper also provides the rainfall and runoff data that was used in the study, but regrettably does not provide the landuse data. Rather than deriving this ourselves following the methods described in the paper, we decided that it would be better to use @levy2018 as a "verfication" of our analysis.   

You are quite right that we need to be clearer about the objectives of the paper and how this is different from the existing work. We agree that there have been many attempts to derive general conclusions in relation to the impact on streamflow of changes to forest cover, as we also discuss in our introduction. However, as we discuss in our response to the Associate Editor, there are considerable issues with the generalisation of such studies (as attempted in @zhou2015; @jackson2005; @filoso2017 and @zhang2017).   
\
\
As a result of this, we have rewritten the scope of the paper and changed the title to better reflect the main findings and message coming from this paper.   
\
\
The new title of the paper is:
**Generalising the impact of forest cover on streamflow from experimental data: it is not that simple.**  
\
The key contribution of this paper is to highlight the knowledge gap that exists in the extrapolation of local studies to effects at the global scale. While the impact of forest cover on streamflow is easily hypothesised [e.g. @zhou2015; @hoekvandijke2022], our research clearly shows that the causal relationship between change in forest cover and streamflow is complex and not as straight forward as shown in earlier literature. In addition, to this we highlight that it is very difficult to reinterpret older studies to isolate the effect of  forestation or deforestation, and in many cases this becomes a qualitative assessment.  
As such, we provide three key insights.  

- While analysing global databases can be interesting, we need to be careful with drawing major conclusions (as in @zhang2017, @filoso2017, @zhou2015 and @jackson2005) based on basic regression analysis or using equilibrium analysis (such as the Fu model). In many cases statistical assumptions are violated and confounding factors can hide or strengthen assumed relationships. In addition, the equilibirum analysis is based on the assumption of water balance closure, which might not always be the case in arid and semi-arid climates. It can easily become a case of 'correlation without causation'. This is without considering the number of errors that existed in the data. This is particularly important, since results from these global analyses are used to build further models to analyse global impacts [e.g. @hoekvandijke2022], leading to possible wrong policy or management responses.  
- Cumulative and average values of change can be misleading, especially when extracted from published field studies which originally had different objectives. This is particularly true for quite a few studies which focused on regeneration of forests after wildfire or clear cutting followed by re-establishment of plantation of native forest. Many of the Paired Watershed Experiments in Australia [e.g. @cornish2001; @webb2009; @webb2012; @webb2013; @watson2001] fall in this category, and therefore easily be classified as either forestation or deforestation. In principle a decision needs to be made how many years post clearing needs to be considered, and whether the remainder of the timeseries should be classified as regeneration. We demonstrate how removing these experiments from the total changes the results of the analysis.
- In general, the size of the catchment and the length of the study play a huge role in the interpretation of the results. The length of the study relates to the last point, in all cases, there is large change in the streamflow in the first year, but this effect decreases with the length of the study due to either natural regeneration or some sort of other management, such as replanting. In terms of the catchment size, one of the key issues we originally had with the @zhang2017 paper was the arbitrary split between catchment > 1000 km^2^ and catchment < 1000 km^2^. Our analysis demonstrates that there is no indication of a distinct split, but that, more importantly there is a distinct difference in the type of methods used to analyse small catchments (mostly direct observation and paired catchment analysis) and large catchments (mostly hydrological modelling or some sort of statistical modelling). The paper by @beck2013 is an exception, focussing on hydrological model analysis of 12 small catchments in Puerto Rico. However, as we argue, the results of this paper are misrepresented in the database, as none of the analysed catchments had a significant change in the streamflow. This means the change should be recorded as 0.   
\

\textcolor{blue}{These are substantial changes and go beyond a major revision.  For this reason, we're rejecting the MS at present.  If the authors are able to address the 3 issues above in a substantial revision of the MS, we would be pleased to look at it again.}
\
We acknowledge this, and we hope that the current revised version and our responses address these concerns.   
\
\textcolor{blue}{We would, however, consider as a new submission for review a substantially revised version of this paper that addresses all of the reviewers' comments.  Should you choose to submit such a revised manuscript please refer to the present manuscript number, provide a detailed point-by-point reply to all of the reviewers' comments, and state how the revised manuscript addresses these.}
\
We acknowledge this, and we hope that the current revised version and our responses address these concerns. 
\

# Associate Editor:

\textcolor{blue}{The manuscript considers an enhanced dataset of streamflow and forest cover, to explore how deforestation/afforestation alters catchment water yields. The manuscript is potentially of interest of the JoH readership, but it is not ready for review in present form.}  
\
<!-- answer -->
Thank you, we acknowledge this and we hope that our current revision and answers to your comments have improved the manuscript sufficiently to go out for further review.  
\
\textcolor{blue}{The main aspects that need to be addressed before the manuscript can be evaluated by experts in the field are listed here. 
- As apparent from the diagnostic plots, the model assumptions may be violated in many cases. This can make the results of the fitting (and hence the manuscript conclusions) incorrect. I urge the authors to double check if this is indeed the case and consider ways to address the problem. It is also good practice to check the relevance of outliers (of data with high VIF) and set them aside before model fitting. It is also not correct to comment on models as if working better or worse in certain ranges, based on the residuals (P 29), because the residuals are the results of the data and fitted model, and the fitted model depends on all datapoints.}  
\
### error distributions
<!-- answer -->
Thank you for raising these important points in relation to the validity of the statistical model. 
A first point that arises from this is that we clarify better what the aim of our statistical modelling is.  
There are in essence two approaches to statistical modelling. Generally a model is developed to be used in predictive mode: using a model to predict unknown values, either within or beyond the current data set (forecasting). In this case the model should be reduced to its most efficient version that minimises the bias - variance trade-off. Automatic variable selection and potentially validation on independent data are therefore important, as the aim is to develop the most robust model for prediction.  
However, a second reason for to use a statistical model is to explain the maximum variance in the data. In this case, it is important to develop a a-priori hypothesis about the causal relationships in the data. This is subsequently followed by a step by step analysis to test the different causal relationships, either as single variables (as was done in @zhang2017) or jointly (as in our approach). In this case there is no attempt to find the best predictive model, instead the focus is on the additional amount of explained variance from adding each variable.  
This explains why we build the model starting from the most simple model, rather than starting from the most complex model.  

\
**Include a section in the paper to explain this clearly**  
\

Either way, understanding the diagnostic plots and the residual distribution is important, which is why this was included in the manuscript. In many cases, including such diagnostic plots for single variable regressions is often omitted. For example, both @zhang2017 and @filoso2017 do not present any diagnostics for their relationships and the regressions (Fig 2 - Fig 4 in @zhang2017 and Fig 9 in @filoso2017) qualitatively indicate issues with the residuals.

In our case, we clearly indicate the steps we have taken to improve the quality of the regressions, such as transforming some of the variables, or explaining why we did not take any further steps. 

### the issue of outliers

**Check Venables and Ripley p119**
"Outliers are sample values that cause surprise in relation to the majority of the sample. This is not a pejorative term; outliers may be correct, but they should always be checked for transcription errors." 
Because our modelling is focused on explaining the maximum variance, we believe that excluding values that are outliers is probably not a good idea.  
\
However, another careful review of the data identified many further errors in the data, which were all originally in @zhang2017. A particular problem was that many catchments had the wrong sign for the change in forest cover. There are many catchments with reported positive change in cover and a large increase in flow. These were all checked and corrected if needed and a full list of all these changes is below:  

- 124, D3, Amatya and Skaggs, 2008: The originally recorded 250\% change by @zhang2017 is clearly wrong. The paper says on page 7: Both of these outflow ratios (0.64 and 0.50) were higher than the calculated expected values of 0.55 for 2003 and 0.44 for 2005, respectively. So value should be $0.64/0.55*100 - 100$ or $0.5/044*100 - 100$: 16\% or 13\%. corrected to 16\%
- 3, Baker Creek, Zhang and Wei, 2012. The original recorde 201.1\% change by @zhang2017 is also wrong. Original paper says on page 2031: Annual mean flow has been increased by 47.6\%. corrected  
- 67, April rd, which is incorrectly attributed to Ruprecht and Schofield (1991) in @zhang2017. This is actually from Ruprecht and Schofield (1989) and the original paper clearly indicates "clearfelling". As a result the change in forest cover was changed to -100\% rather than +100\%.  
- 210, March rd, 100, 147.6. Same problem as 67, Bari et al. (1996) clearly state that the catchment was cleared, so therefor the change in forest cover changed to -100\%.  
- 213, 214 and 215, Monda 1, 2 and 3. These catchments are tricky. The original paper [@oshaughnessy1979] only reports on the control period and indicates that the catchments will be cleared. The later summary paper [@watson2001] shows the timeseries of the flow change, but does not report a single value, so the values in the database must have been estimated from the timeseries. The further complication is that the treatment included clearing and reseeding and regrowth. This suggest that the records should be removed from the database, or only the first few years of the experiment used. In any case, if the values are kept, the sign of the change in forest cover needs to changed to negative (Clearing).  
- 230, Oleolega catchment. The paper describes a removal of forest up to 85\%. changed Delta_F_perc to -85 from 90.  
- 312, Yerraminup South. The original publication for this catchment is a Western Australian Water Authority report from 1987, which is hard to find, but we have added a copy in the "Papers" folder on github. In this report, in Table 2 on page 11, for the catchment a "Crown cover" decrease of 60\% is given. Changed the sign of the change in forest cover: -60\%.  
- 72 Barratta, 100 Coachwood, 103 Corkwood, and 83 Bollygum, as cited by @cornish1993 and @cornish2001. In the database from @zhang2017, the forest change for all these catchments is positive. However, the paper highlights that these catchments were all logged and either naturally regenerated or were planted with a plantation species. So, similar to the the earlier mentioned Monda catchments, the reported change probably only refers to the first couple of years after clearing (before regrowth). In any case, the reported change in forest cover should be negative (clearing) rather than positive. Corrected for all three catchments.  
- 78, Black Spur 1, the treatments and effects are only reported in a conference paper [@jayasuriya1988] and once again indicated clearing, meaning that the change in forest cover should be negative rather than positive (as reported in @zhang2017). Corrected. Similar to other paired watershed experiments, only the first couple of years can be linked to the effect as later regrowth cancels out part of the increase in flow.  
- 104, Coshocton. Checking the original paper indicates that this is in fact a reduction in flow as a result of reforestation. Changed the sign of Delta_Q_f to be negative.  
- 102, Cold Spring. Checking the original paper [@schneider1961] indicates that this is in fact a reduction in flow as a result of reforestation. Changed the sign of Delta_Q_f to be negative.  
- 85 Bosboukloof. This is esssentially a duplicate of 184, but the cited paper analyses only 1 year of runoff after a major fire. In any case, the data should reflect a decrease in forest cover: changed the sign of Delta_f_perc to -80\%.   
- 259 Shackam Brook. There were a few issues with this catchment in the original database. The name was misspelled and it was incorrectly attributed to @brown2005. The original paper is the same as 102 [@schneider1961]. Finally, the catchments were all reforestation as the title of the original report indicates and the reported streamflows are all decreases. Corrected Delta_Qf_perc to -20.7\%.  
- 95 Sage Brook. Similar to 259 and 102, originates from @schneider1961. Reforestation so Delta_Qf_perc corrected to -19.8\%.  
- 101 Coalburn. Original publication (Robinson, 1993) which is a symposium paper, is not available. The best summary of the research is in @birkinshaw2014 which summaries 45 years of resaerch in the Coalburn catchment. It was a reforestation experiment, and there was a decrease in the streamflow over the longer time period. Changed to -20.3\%.  

A final issue was the inclusion of the results of several catchments, for example from the study by @beck2013, which had no significant change in flow. Despite this, the "average" change in flow was reported int he database. We don't believe that this is correct and the results from such studies should be set to 0. A full list of changes is provided below:

- 97 Cibucio, 123 Culebrinas, 244 Portugues, 161 Grande de Loıza, 271 Tanama, 132 Fajardo, 89 Canovanas, 73, Bauta, 163 Grande de Patillas, 283 Valenciano, 181 Inabon, and 162 Grande de Manati. These are all catchments in Puerto Rico from the study from @beck2013. They should probably be removed from the database as the paper clearly indicates that there is no evidence of a change in flow due to reforestation. The values that are cited in the database should all be set to "not significant from 0", so might be included as 0. Including them with positive or negative values is misleading. This study is a very detailed hydrological modelling study, but in the end finds no significant change in streamflow as a result of deforestation. Values for all 12 studied catchments set to 0 in the database.  
- 188 Kimakia
- 221	N. Creek, Babinda, Queensland
- 254 Sambret

There were similar studies that we identified that

## VIF analysis and understanding cross correlations between the variables


A VIF analysis is also a great suggestion as this will indicate variables which are highly correlated within the dataset, such as the Precipitation and Dryness (which we already indicate).

```{r}
require(mgcv)
require(car)

All_data <- read_csv("All_data.csv")
All_data2 <- read_csv("All_data2.csv")
All_data2 <- All_data2 %>%
  mutate(length = To - From,
         mid_year = From + (To - From)/2)

#Maybe first simply
# https://stackoverflow.com/questions/52554336/plot-the-equivalent-of-correlation-matrix-for-factors-categorical-data-and-mi
library(ggcorrplot)
png("testcorr_plot.png", width = 960, height = 960)
model.matrix(~0+DeltaF_perc_pos + 
                    Forest_Sign + 
                   log10(Area_km2) + 
                    Dryness + 
                    length +
                    Precip_data_type +  Assessment_technique +
                    Forest_type +
                    Hydrological_regime, data=All_data2) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot(show.diag = F, type="lower", lab=TRUE, lab_size=4)
dev.off()

# model6_all <- gam(DeltaQf_perc ~ DeltaF_perc_pos + 
#                     Forest_Sign + 
#                    log10(Area_km2) + 
#                     Dryness + 
#                     length +# s(From, k = 40, bs = "ts") +
#                     Precip_data_type +  Assessment_technique +
#                     Forest_type +
#                     Hydrological_regime
#                     , data = All_data2)
# summary(model6_all)
# gam.check(model6_all)
# #plot(model6_all)
# inf1 = influence.gam(model6_all)
# hist(inf1)
# hist(cooks.distance(model6_all))
# which.max(cooks.distance(model6_all))
# 
# regclass::VIF(model6_all)
# 
# # Can only do car::vif on linear model and only on numerical values
# car::vif(gam(DeltaQf_perc ~ DeltaF_perc_pos + Forest_Sign + 
#                     log10(Area_km2) + 
#                     Dryness + 
#                     length, data = All_data2))
```


```{r corgraphs, echo=F, out.width="90%", fig.cap="Correlation matrix for all variables"}

include_graphics("./testcorr_plot.png")
```
So the VIF really does not work, only works for numerical values and not for factor values. So this suggestion is not really relevant either.

However, being too focused on just the residual distribution can also lead to over fitting or over smoothing of the variables. This means that important characteristics of the data might be lost. 


\textcolor{blue}{- The manuscript presents a number of alternative statistical models, differing by candidate explanatory variables. Each model is designed considering the key shortcomings of the previous one. The end result of such an approach is a complex and somewhat non systematic exploration of predictors and their explanatory power, where it is easy to get lost. I suggest restructuring the manuscript around a well-designed and robustly formalized model selection. One way to proceed could be to start with the most complex model suggested by the extant understanding of the processes at play, and then proceed with a model simplification, according to some consistent criteria (AIC, dropping non significant terms, or similar; high r2 is not a good criterion because it does not consider the number of parameters). A full blown model selection would also allow to retain or discard the interaction terms, which could be important (as also recognized by the authors; Section 4.5) and should not be discarded a priori. Doing a proper model selection and presenting the results only for the best model (according to a clearly specified criterion) would be less subjective and allow to drastically reduce the number of figures and tables, allowing the reader to focus their attention on the key message.}  
\
<!-- answer -->
As outlined in the last part of the reply, the focus of the statistical modelling in the paper is on understanding the different covariates that can explain the variation in the data.   
\

\textcolor{blue}{- The novelty of this work needs to emerge more clearly in the introduction. As it looks now, the manuscript could be easily considered somewhat confirmatory, with respect to most data, approaches and conclusions reached by Zhang et al 2017 and Filoso et al 2017. Furthermore, the introduction needs to be rearranged, starting with a clear statement of the problem, what we know about that based on previous results, what is missing/how these previous analyses can be improved, and, stemming from these knowledge gaps and/or our understanding of the mechanisms, the questions addressed in the work or the hypotheses tested.}  
\
<!-- answer -->
This is a good point and we have rewritten the paper to strengthen this point.  
\

\textcolor{blue}{There are also some typos and unfinished sentences (e.g., L 142, L 298). Some units are missing (for example those of length of the experiment in the figures) and symbols are not defined at their first appearance (E0/Pa in L 99; Dryness Index). Also: how is Table 1 used? These are not big issues per se but are nonetheless distracting.}

\textcolor{blue}{I would also like to provide the authors with a couple of suggestions regarding the statistical model and their interpretation. 
- The models used in the manuscript consider the absolute value of the forest cover change and then its sign, but this choice is not well justified. It implicitly assumes that the status corresponding to no change distinguishes two ‘realms’. Yet, I would expect (and it is also hinted at at some point in the manuscript) that what really matters is the \%forested area (possibly in relation to the climatic conditions) and how it changes. So, I would suggest the authors to consider whether a model nearer to our understanding of the phenomena at play would be one including, for the forest part, \%change in forested area (with sign) and \%forested area, with the latter possibly as random effect, if not of interested.}


\textcolor{blue}{- The fact that the explanatory power is low (low r2) does not necessarily make the results uninteresting (against conclusion on L 530), simply it suggests there are other factors, not included in the model, which have a large effect, and that the model presented cannot be used in a predictive mode. While it is important to present also the r2, even a model with low r2 square we learn which factors significantly affect the change in streamflow and which do not do so.}

